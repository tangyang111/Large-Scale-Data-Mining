{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Ridge Regularizer\n",
      "Optimal Combination:\n",
      "use_one_hot: ['day_of_week', 'start_time', 'work_flow']\n",
      "use_scalar: ['week', 'file_name']\n",
      "Optimal Alpha: 5\n",
      "Optimal Test Rmse: 0.0883677380035\n",
      "estimated coefficients: \n",
      "[  3.92371018e-02  -1.28385492e-02  -2.02296713e-02  -5.23861235e-03\n",
      "  -5.69522387e-03   3.27107576e-03   1.49387908e-03  -2.01731751e-02\n",
      "  -2.10260133e-02   7.77904203e-03   3.34016216e-02  -1.98635056e-03\n",
      "   2.00487535e-03   3.88772567e-02  -1.36944804e-02  -4.01480968e-02\n",
      "  -5.71822376e-02   7.21475581e-02   1.12198388e-05   5.87765230e-05]\n",
      "-----------------------------------------\n",
      "using Lasso Regularizer\n",
      "Optimal Combination:\n",
      "use_one_hot: ['week', 'day_of_week', 'start_time', 'work_flow', 'file_name']\n",
      "use_scalar: []\n",
      "Optimal Alpha: 0.001\n",
      "Optimal Test Rmse: 0.0888033150298\n",
      "estimated coefficients: \n",
      "[ -7.89378832e-04  -3.97987629e-05   3.50273462e-04  -3.50408399e-04\n",
      "   3.30577856e-04  -2.13416268e-04   8.20825549e-06   8.23510457e-04\n",
      "   1.26465661e-04   1.23745592e-04  -5.69967202e-04   7.22425669e-04\n",
      "  -1.84632908e-04  -1.14632874e-05  -3.26141889e-04   3.93117111e-02\n",
      "  -1.28639774e-02  -2.02670034e-02  -5.24818883e-03  -5.70655632e-03\n",
      "   3.27725480e-03   1.49676768e-03  -2.02050649e-02  -2.10615321e-02\n",
      "   7.79151188e-03   3.34547540e-02  -1.98706723e-03   2.00741659e-03\n",
      "   3.27638144e-02  -1.20563131e-02  -3.44588984e-02  -4.87757697e-02\n",
      "   6.25272312e-02   4.74142587e-03   5.99085364e-03   5.66125491e-03\n",
      "   5.63475837e-03   5.24421656e-03   5.49130147e-03  -1.62341162e-03\n",
      "  -2.10708489e-03  -1.89836804e-03  -2.18193696e-03  -2.28671168e-03\n",
      "  -1.95879803e-03  -6.48654465e-03  -6.07490112e-03  -5.60116924e-03\n",
      "  -6.66748266e-03  -4.14978568e-03  -5.47899716e-03  -8.28995617e-03\n",
      "  -7.96287188e-03  -7.90399935e-03  -8.26363303e-03  -8.31223878e-03\n",
      "  -8.04309515e-03   1.01612981e-02   1.07247021e-02   1.09141982e-02\n",
      "   9.84795292e-03   1.04940610e-02   1.03849672e-02]\n",
      "-----------------------------------------\n",
      "using Elastic Net Regularizer\n",
      "Optimal Combination:\n",
      "use_one_hot: ['week', 'day_of_week', 'start_time', 'work_flow', 'file_name']\n",
      "use_scalar: []\n",
      "Optimal Alpha1: 1e-05\n",
      "Optimal Alpha2: 0.00999\n",
      "Optimal Test Rmse: 0.0889835690943\n",
      "estimated coefficients: \n",
      "[ -5.47613163e-04  -0.00000000e+00   1.85837480e-04  -1.62756136e-04\n",
      "   1.63718609e-04  -4.64811103e-05   0.00000000e+00   5.97510939e-04\n",
      "   0.00000000e+00   0.00000000e+00  -3.52168422e-04   5.07015899e-04\n",
      "  -1.99188348e-05   0.00000000e+00  -1.38659992e-04   3.67874154e-02\n",
      "  -1.17706627e-02  -1.87687608e-02  -4.71642638e-03  -5.11965214e-03\n",
      "   3.13152974e-03   1.46559163e-03  -1.90361249e-02  -1.97663581e-02\n",
      "   7.29075431e-03   3.15254988e-02  -1.90049483e-03   1.85158202e-03\n",
      "   3.23900707e-02  -1.18769001e-02  -3.33756988e-02  -4.71304450e-02\n",
      "   6.09671235e-02   4.01513708e-03   4.97271621e-03   4.72163425e-03\n",
      "   4.70127791e-03   4.40130394e-03   4.58776338e-03  -8.49238118e-04\n",
      "  -1.21859984e-03  -1.05921285e-03  -1.27576343e-03  -1.35577652e-03\n",
      "  -1.10536401e-03  -5.30775494e-03  -4.97963328e-03  -4.61440285e-03\n",
      "  -5.43854606e-03  -3.50087906e-03  -4.52619630e-03  -7.14509952e-03\n",
      "  -6.89247276e-03  -6.84699925e-03  -7.12475884e-03  -7.16229616e-03\n",
      "  -6.95441990e-03   9.12569157e-03   9.56084119e-03   9.70720324e-03\n",
      "   8.88369399e-03   9.38272003e-03   9.29846630e-03]\n",
      "-----------------------------------------\n",
      "using un-regularized best model\n",
      "estimated coefficients: \n",
      "[  1.27121601e+11   1.27121601e+11   1.27121601e+11   1.27121601e+11\n",
      "   1.27121601e+11   1.27121601e+11   1.27121601e+11   5.28985666e+10\n",
      "   5.28985666e+10   5.28985666e+10   5.28985666e+10   5.28985666e+10\n",
      "   5.28985666e+10  -5.61826018e+09  -5.61826018e+09  -5.61826018e+09\n",
      "  -5.61826018e+09  -5.61826018e+09  -5.61826018e+09  -3.60363106e+09\n",
      "  -3.60363106e+09  -3.60363106e+09  -3.60363106e+09  -3.60363106e+09\n",
      "  -3.60363106e+09  -1.58900195e+09  -1.58900195e+09  -1.58900195e+09\n",
      "  -1.58900195e+09  -1.58900195e+09  -1.58900195e+09   4.25627173e+08\n",
      "   4.25627173e+08   4.25627173e+08   4.25627173e+08   4.25627173e+08\n",
      "   4.25627173e+08   2.44025629e+09   2.44025629e+09   2.44025629e+09\n",
      "   2.44025629e+09   2.44025629e+09   2.44025629e+09   1.23977661e-05\n",
      "  -2.01462912e+09]\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# load data from file\n",
    "data = pd.read_csv('network_backup_dataset.csv')\n",
    "data.columns = ['week', 'day_of_week_orig', 'start_time','work_flow_orig','file_name_orig','size','duration']\n",
    "\n",
    "def replace_str_with_int(data, column, insert_pos, truncate_pos=0, map_day=None):\n",
    "    new_col = []\n",
    "    for item in data[column]:\n",
    "        if map_day:\n",
    "            new_col.append(map_day[item])\n",
    "        else:\n",
    "            new_col.append(int(item[truncate_pos:]))\n",
    "    \n",
    "    data.insert(insert_pos, column[:len(column) - 5], new_col)\n",
    "    data.drop(column, 1, inplace = True)       \n",
    "\n",
    "# 1 encode day of week\n",
    "map_day = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7}\n",
    "replace_str_with_int(data, 'day_of_week_orig', 2, 0, map_day)\n",
    "\n",
    "# 2 encode work flow\n",
    "replace_str_with_int(data, 'work_flow_orig', 3, 10)\n",
    "\n",
    "# 3 encode file name\n",
    "replace_str_with_int(data, 'file_name_orig', 4, 5)\n",
    "\n",
    "# extract input and output\n",
    "input_arr = []\n",
    "for row in range(len(data)):\n",
    "    input_arr.append(data.loc[row, 'week':'file_name'].values)\n",
    "\n",
    "output_arr = data.loc[:, 'size'].values\n",
    "\n",
    "def one_hot_encoding(input_arr, one_hot_pos):\n",
    "    enc = OneHotEncoder(n_values='auto', categorical_features=one_hot_pos, \n",
    "                        sparse=False, handle_unknown='error')\n",
    "    return enc.fit_transform(input_arr)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def find_optimal_combination(input_arr, alg, kf_split=10, num_combines=32):\n",
    "    # return values of this function\n",
    "    best_test_rmse = float(\"inf\")\n",
    "    best_combination = 0\n",
    "    \n",
    "    kf = KFold(n_splits=kf_split, shuffle=False)\n",
    "    for combine in range(num_combines):\n",
    "        # 00000~11111 (0~31) using bit operation\n",
    "        one_hot_pos = []\n",
    "        for pos in range(5):\n",
    "            if ((combine >> pos) & 1) == 1:\n",
    "                one_hot_pos.append(pos)\n",
    "        tranformed_input = one_hot_encoding(input_arr, one_hot_pos)\n",
    "\n",
    "        test_rmses = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(tranformed_input):\n",
    "            \n",
    "            train_in = [tranformed_input[i] for i in train_index]\n",
    "            train_out = [output_arr[i] for i in train_index]\n",
    "            test_in = [tranformed_input[i] for i in test_index]\n",
    "            test_out = [output_arr[i] for i in test_index]\n",
    "\n",
    "            alg.fit(train_in, train_out)\n",
    "            test_pre = alg.predict(test_in)\n",
    "\n",
    "            test_rmses.append(rmse(test_pre, test_out))\n",
    "\n",
    "        mean_test_rmse = np.mean(test_rmses)\n",
    "        \n",
    "        if mean_test_rmse < best_test_rmse:\n",
    "            best_test_rmse = mean_test_rmse\n",
    "            best_combination = combine\n",
    "\n",
    "    return best_combination, best_test_rmse\n",
    "\n",
    "def combinaton_trans(combine):\n",
    "    variables = ['week','day_of_week','start_time','work_flow','file_name']\n",
    "    use_one_hot = []\n",
    "    use_scalar = []\n",
    "    for pos in range(5):\n",
    "            if ((combine >> pos) & 1) == 1:\n",
    "                use_one_hot.append(variables[pos])\n",
    "            else:\n",
    "                use_scalar.append(variables[pos])\n",
    "    return 'use_one_hot: ' + str(use_one_hot) + '\\nuse_scalar: ' + str(use_scalar)\n",
    "\n",
    "# Ridge Regularizer & Lasso Regularizer\n",
    "def Ridge_Lasso_Regularizer(name):\n",
    "    print('using ' + name)\n",
    "    best_combine = None\n",
    "    lowest_rmse = float(\"inf\")\n",
    "    optimal_alpha = 1\n",
    "    for alpha in [0.001, 0.01, .1, .5, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        reg = None\n",
    "        if name == 'Ridge Regularizer':\n",
    "            reg = linear_model.Ridge (alpha = alpha)\n",
    "        else:\n",
    "            reg = linear_model.Lasso(alpha=alpha)\n",
    "        best_combination, best_test_rmse = find_optimal_combination(input_arr, reg, kf_split=10, num_combines=32)\n",
    "        if best_test_rmse < lowest_rmse:\n",
    "            best_combine = best_combination\n",
    "            lowest_rmse = best_test_rmse\n",
    "            optimal_alpha = alpha\n",
    "\n",
    "    print ('Optimal Combination:')\n",
    "    print (combinaton_trans(best_combine)) \n",
    "    print ('Optimal Alpha: ' + str(optimal_alpha))\n",
    "    print ('Optimal Test Rmse: ' + str(lowest_rmse))\n",
    "\n",
    "    one_hot_pos = []\n",
    "    for pos in range(5):\n",
    "        if ((best_combine >> pos) & 1) == 1:\n",
    "            one_hot_pos.append(pos)\n",
    "    tranformed_input = one_hot_encoding(input_arr, one_hot_pos)\n",
    "\n",
    "    alg = linear_model.Ridge (alpha = optimal_alpha)\n",
    "    alg.fit(tranformed_input, output_arr)\n",
    "    print ('estimated coefficients: ')\n",
    "    print (str(alg.coef_))\n",
    "    print ('-----------------------------------------')\n",
    "\n",
    "Ridge_Lasso_Regularizer('Ridge Regularizer')\n",
    "Ridge_Lasso_Regularizer('Lasso Regularizer')\n",
    "\n",
    "# Elastic Net Regularizer:\n",
    "print('using ' + 'Elastic Net Regularizer')\n",
    "best_combine = None\n",
    "lowest_rmse = float(\"inf\")\n",
    "optimal_alpha = .2\n",
    "optimal_l1_ratio = 0.001\n",
    "for alpha in [0.01, 0.1, 1, 10, 100]:\n",
    "    for l1_ratio in [0.1, 0.5, 0.9]:\n",
    "        reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        best_combination, best_test_rmse = find_optimal_combination(input_arr, reg, kf_split=10, num_combines=32)\n",
    "        if best_test_rmse < lowest_rmse:\n",
    "            best_combine = best_combination\n",
    "            lowest_rmse = best_test_rmse\n",
    "            optimal_alpha = alpha\n",
    "\n",
    "print ('Optimal Combination:')\n",
    "print (combinaton_trans(best_combine)) \n",
    "print ('Optimal Alpha1: ' + str(optimal_alpha * optimal_l1_ratio))\n",
    "print ('Optimal Alpha2: ' + str(optimal_alpha * (1-optimal_l1_ratio)))\n",
    "print ('Optimal Test Rmse: ' + str(lowest_rmse))\n",
    "\n",
    "one_hot_pos = []\n",
    "for pos in range(5):\n",
    "    if ((best_combine >> pos) & 1) == 1:\n",
    "        one_hot_pos.append(pos)\n",
    "tranformed_input = one_hot_encoding(input_arr, one_hot_pos)\n",
    "\n",
    "alg = ElasticNet(alpha=optimal_alpha, l1_ratio=optimal_l1_ratio)\n",
    "alg.fit(tranformed_input, output_arr)\n",
    "print ('estimated coefficients: ')\n",
    "print (str(alg.coef_))\n",
    "print ('-----------------------------------------')\n",
    "\n",
    "# using un-regularized best model\n",
    "print('using un-regularized best model')\n",
    "\n",
    "best_combine = 22\n",
    "one_hot_pos = []\n",
    "for pos in range(5):\n",
    "    if ((best_combine >> pos) & 1) == 1:\n",
    "        one_hot_pos.append(pos)\n",
    "tranformed_input = one_hot_encoding(input_arr, one_hot_pos)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(tranformed_input, output_arr)\n",
    "\n",
    "print ('Optimal Combination:')\n",
    "print (combinaton_trans(best_combine))\n",
    "print ('Optimal Test Rmse: 0.0883701294703')\n",
    "print ('estimated coefficients: ')\n",
    "print (str(lr.coef_))\n",
    "print ('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
